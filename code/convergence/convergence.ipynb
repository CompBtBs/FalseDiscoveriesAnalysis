{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d793f694-13ae-4fc3-bc61-ce3a18fb2da0",
   "metadata": {},
   "source": [
    "convergence.ipynb  Convergence analysis\n",
    "\n",
    "    Version 1.0 February 2023\n",
    "\n",
    "    Authors: \n",
    "        - Bruno G. Galuzzi <bruno.galuzzi@unimib.it> (Department of Biotechnology and Biosciences, University of Milano-Bicocca)\n",
    "        - Luca Milazzo <l.milazzo1@campus.unimib.it> (Department of Informatics, Systems, and Communications, University of Milano-Bicocca)\n",
    "        - Chiara Damiani <chiara.damiani@unimib.it> (Department of Biotechnology and Biosciences, University of Milano-Bicocca)\n",
    "\n",
    "    Prerequisites and parameters:\n",
    "         - Install all the modules listed under the \"Libraries\" chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae8b35-d8fe-4ca1-8067-6cedcbeacafa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e98112f-eb84-4c44-bf3e-8bc23c5a4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra as cb\n",
    "import logging\n",
    "logging.basicConfig(filename=\"log.txt\"  , level=logging.INFO)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93827562-acee-4cc0-b94c-8a1cc8b8a5de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5e0a86-8bf2-46a2-bf01-84476842dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\"ENGRO 1\", \"ENGRO 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ba11c6-4f53-484f-b1c6-2c706786222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Create a folder if it doesn't already exist\n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def createFolder(path):\n",
    "    if not os.path.exists(path):\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e68ab4-a785-4627-8387-142a6ef2166a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51aeede8-a2a1-4c5b-9f0c-99b58db76276",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Load the models files (.xml)\n",
    "# Parameters\n",
    "# - modelNames --> list of models names that must\n",
    "# match the file names\n",
    "# - modelFolder --> the folder containing the \n",
    "# models files\n",
    "##############################################\n",
    "def loadModels(modelNames, modelFolder):\n",
    "    models = {}\n",
    "    for modelName in modelNames:\n",
    "        files = os.listdir(modelFolder)\n",
    "        found = False\n",
    "        for file in files:\n",
    "            filename, extension = os.path.splitext(file)\n",
    "            if(filename == modelName):\n",
    "                found = True\n",
    "                break\n",
    "        if(found):\n",
    "            if(extension == \".xml\"):\n",
    "                models[modelName] = cb.io.read_sbml_model(modelFolder + filename + extension)\n",
    "            else:\n",
    "                raise ImportError('Model file extension not supported')\n",
    "        else:\n",
    "            raise FileNotFoundError('File not found')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a273e0a4-f456-43a2-8b1c-d20ded7ec25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsDict = loadModels(modelNames, \"../../models/\")\n",
    "modelReactionsDict = {}\n",
    "for modelName in modelNames:\n",
    "    listReactions = []\n",
    "    for reaction in modelsDict[modelName].reactions:\n",
    "        listReactions.append(reaction.id)\n",
    "    modelReactionsDict[modelName] = listReactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be7407-ea4d-4369-8fc0-916af360296d",
   "metadata": {},
   "source": [
    "# Convergence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "362c365e-286d-4f4d-9912-0b21c40bf3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultIndexAnalysis(test, value, cont):\n",
    "    if(test == \"geweke\"):\n",
    "        if(not (math.isnan(value))):\n",
    "            if(abs(value) > 1.28):\n",
    "                cont +=1\n",
    "                return (cont)\n",
    "            else:\n",
    "                return (cont)\n",
    "    elif(test == \"raftery-lewis\"):\n",
    "        if(not (math.isnan(value))): # if nan --> chain too short\n",
    "            if(abs(value) > 5):\n",
    "                cont +=1\n",
    "                return (cont)\n",
    "            else:\n",
    "                return (cont)\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "\n",
    "\n",
    "##############################################\n",
    "# It analyses the coefficients produced by convergence.r\n",
    "# to create a dataframe in which each row, representing \n",
    "# a fixed number of samples, contains the fraction of times \n",
    "# in which the hypotesis of convergence must be rejected \n",
    "# for each model reaction. The last column\n",
    "# of the dataframe contains the cross-reaction fraction for \n",
    "# a fixed number of samples (mean of the row fractions).\n",
    "# Parameters\n",
    "# - modelNames --> list of modelNames\n",
    "# - modelsDict --> models dictionary\n",
    "# - modelReactionsDict --> models reactions dictionary\n",
    "# - tests --> diagnostics to use\n",
    "# - samplesNDict --> samples dictionary for the algorithms\n",
    "# - executionsPerSampleSize --> executions per sample size\n",
    "# - executionsCbs3 --> executions of the CBS3 algorithm\n",
    "# - thinningsDict --> thinnings dictionary\n",
    "# - convergenceFolder --> folder of the convergence coefficients\n",
    "# - avoidBlockedReactions --> if True, the cross-reaction mean\n",
    "# does not take into account the coefficients of blocked reactions\n",
    "##############################################\n",
    "def convergenceAnalysis(modelNames, modelsDict, modelReactionsDict, tests, \n",
    "                        samplesNDict,executionsPerSampleSize, executionsCbs3, thinningsDict,convergenceFolder, avoidBlockedReactions):\n",
    "    \n",
    "    for modelName in modelNames:\n",
    "        nReaction = len(modelReactionsDict[modelName])\n",
    "        columns = [\"Samples\"]\n",
    "        columns.extend(modelReactionsDict[modelName])\n",
    "        columns.append(\"Total\")\n",
    "        \n",
    "        if(avoidBlockedReactions):\n",
    "            blockedR = cb.flux_analysis.find_blocked_reactions(modelsDict[modelName])\n",
    "            nBlockedR = len(blockedR)\n",
    "        \n",
    "        for algorithm in algorithms:\n",
    "            for thinning in thinningsDict[algorithm]:\n",
    "                for test in tests:\n",
    "                    if(algorithm == \"cbs3\"):\n",
    "                        analysisFolder = os.path.join(convergenceFolder, modelName, test, algorithm + \"groupedBy\" + str(thinning), \"analysis\")\n",
    "                    else:\n",
    "                        analysisFolder = os.path.join(convergenceFolder, modelName, test, algorithm + \"Thinning\" + str(thinning), \"analysis\")\n",
    "                    \n",
    "                    createFolder(analysisFolder)\n",
    "                    lenDf = 0\n",
    "                    df_result = pd.DataFrame(columns =  columns)\n",
    "                    contCbs3 = 0\n",
    "                    for nSample in samplesNDict[algorithm]:\n",
    "                        cont =  [0] * nReaction\n",
    "                        \n",
    "                        if(algorithm == \"cbs3\"):\n",
    "                            executionsPerSampleSizeToUse = executionsCbs3\n",
    "                        else:\n",
    "                            executionsPerSampleSizeToUse = executionsPerSampleSize\n",
    "                        \n",
    "                        for nRun in range(0, executionsPerSampleSizeToUse):\n",
    "                            if(algorithm == \"cbs3\"):\n",
    "                                filePath =  os.path.join(convergenceFolder, modelName, test, algorithm + \"groupedBy\" + str(thinning), \n",
    "                                                         str(nRun) + \"_\" + str(0) + \".csv\") \n",
    "                            else:\n",
    "                                filePath =  os.path.join(convergenceFolder, modelName, test, algorithm + \"Thinning\" + str(thinning), \n",
    "                                                         str(nSample) + \"_\" + str(nRun) + \".csv\") \n",
    "                            df = pd.read_csv(filePath, index_col = 1)\n",
    "                            df.drop(df.filter(regex=\"Unname\"), axis=1, inplace=True)\n",
    "                            j = 0\n",
    "                            for index, row in df.iterrows():\n",
    "                                if(avoidBlockedReactions):\n",
    "                                    if(index not in blockedR):\n",
    "                                        cont[j] = resultIndexAnalysis(test, row['result'], cont[j])\n",
    "                                else:\n",
    "                                     cont[j] = resultIndexAnalysis(test, row['result'], cont[j])\n",
    "                                    \n",
    "                                j = j + 1\n",
    "                                \n",
    "                        for i in range(0, nReaction):\n",
    "                            cont[i] = cont[i] / executionsPerSampleSizeToUse\n",
    "                        if(algorithm == \"cbs3\"):\n",
    "                            listnSample = [contCbs3]\n",
    "                            contCbs3 +=1\n",
    "                        else:\n",
    "                            listnSample = [nSample]\n",
    "                        listnSample.extend(cont)\n",
    "                        summ = 0\n",
    "                        for i in range (0, nReaction):\n",
    "                            if(avoidBlockedReactions):\n",
    "                                if(modelReactionsDict[modelName][i] not in blockedR):\n",
    "                                    summ = summ + cont[i]\n",
    "                            else:\n",
    "                                summ = summ + cont[i]\n",
    "                        if(avoidBlockedReactions):\n",
    "                            listnSample.append(summ/(nReaction - nBlockedR))\n",
    "                        else:\n",
    "                            listnSample.append(summ/nReaction)\n",
    "                        df_result.loc[lenDf] = listnSample\n",
    "                        lenDf = lenDf + 1\n",
    "                    df_result.set_index('Samples').to_csv(os.path.join(analysisFolder, \"analysis.csv\"))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57a7521b-8f30-4b15-8353-dbd79f09fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"achr\", \"optgp\", \"chrr\", \"cbs3\"]\n",
    "tests = [\"geweke\", \"raftery-lewis\"]\n",
    "\n",
    "thinningsDict = {}\n",
    "\n",
    "avoidBlockedReactions = True\n",
    "\n",
    "samplesNDict = {}\n",
    "\n",
    "samplesNList = []\n",
    "\n",
    "for i in range(1000, 30001, 1000):\n",
    "    samplesNList.append(i)\n",
    "    \n",
    "executionsPerSampleSize = 20\n",
    "executionsCbs3 = 20\n",
    "\n",
    "samplesNDict[\"achr\"] = samplesNList\n",
    "samplesNDict[\"optgp\"] = samplesNList\n",
    "samplesNDict[\"chrr\"] = samplesNList\n",
    "samplesNDict[\"cbs3\"] = [1000] * executionsCbs3\n",
    "\n",
    "\n",
    "thinningsDict[\"achr\"] = [1, 10, 100]\n",
    "thinningsDict[\"optgp\"] = [1, 10, 100]\n",
    "thinningsDict[\"chrr\"] = [1, 10, 100]\n",
    "thinningsDict[\"cbs3\"] = [1000]\n",
    "\n",
    "\n",
    "convergenceFolder =\"../../results/convergence/\"\n",
    "\n",
    "convergenceAnalysis(modelNames, modelsDict, \n",
    "               modelReactionsDict,\n",
    "               tests,\n",
    "               samplesNDict,\n",
    "               executionsPerSampleSize,\n",
    "               executionsCbs3,\n",
    "               thinningsDict,\n",
    "               convergenceFolder,\n",
    "               avoidBlockedReactions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
