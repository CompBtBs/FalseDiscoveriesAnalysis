{
 "cells": [
  {
   "cell_type": "raw",
   "id": "76ef9b09-c7b6-403f-9420-ccee3ab9fc92",
   "metadata": {},
   "source": [
    "kld.ipynb  Kullback Leibler Divergence analysis\n",
    "\n",
    "    Version 1.0 February 2023\n",
    "\n",
    "    Authors: \n",
    "        - Bruno G. Galuzzi <bruno.galuzzi@unimib.it> (Department of Biotechnology and Biosciences, University of Milano-Bicocca)\n",
    "        - Luca Milazzo <l.milazzo1@campus.unimib.it> (Department of Informatics, Systems, and Communications, University of Milano-Bicocca)\n",
    "        - Chiara Damiani <chiara.damiani@unimib.it> (Department of Biotechnology and Biosciences, University of Milano-Bicocca)\n",
    "\n",
    "    Prerequisites and parameters:\n",
    "         - Install all the modules listed under the \"Libraries\" chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f1e21-df45-495b-904e-2459334c7e30",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62830f12-5afb-43cc-8d59-591c24d25e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra as cb\n",
    "import logging\n",
    "logging.basicConfig(filename=\"log.txt\"  , level=logging.INFO)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement\n",
    "import scipy.stats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd76c5-1d4f-4bc7-9ed1-a75c973b53ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807f3bb6-b2de-4388-ab4c-23f2e5c3df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\"ENGRO 1\", \"ENGRO 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb98b17-f858-46d7-9d6b-3516ea9a3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Create a folder if it doesn't already exist\n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def createFolder(path):\n",
    "    if not os.path.exists(path):\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a48aca-f10f-4755-8a8a-7085b176bcf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd36dd6a-5a6e-4af0-a485-3903b14cf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Load the models files (.xml)\n",
    "# Parameters\n",
    "# - modelNames --> list of models names that must\n",
    "# match the file names\n",
    "# - modelFolder --> the folder containing the \n",
    "# models files\n",
    "##############################################\n",
    "def loadModels(modelNames, modelFolder):\n",
    "    models = {}\n",
    "    for modelName in modelNames:\n",
    "        files = os.listdir(modelFolder)\n",
    "        found = False\n",
    "        for file in files:\n",
    "            filename, extension = os.path.splitext(file)\n",
    "            if(filename == modelName):\n",
    "                found = True\n",
    "                break\n",
    "        if(found):\n",
    "            if(extension == \".xml\"):\n",
    "                models[modelName] = cb.io.read_sbml_model(modelFolder + filename + extension)\n",
    "            else:\n",
    "                raise ImportError('Model file extension not supported')\n",
    "        else:\n",
    "            raise FileNotFoundError('File not found')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "583155f9-0ea4-4e6f-b32c-83361e8f6632",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsDict = loadModels(modelNames, \"../../models/\")\n",
    "modelReactionsDict = {}\n",
    "for modelName in modelNames:\n",
    "    listReactions = []\n",
    "    for reaction in modelsDict[modelName].reactions:\n",
    "        listReactions.append(reaction.id)\n",
    "    modelReactionsDict[modelName] = listReactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46cdc9-db83-4643-8e25-3816ae34fee0",
   "metadata": {},
   "source": [
    "# KLD analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83ef7724-c8e4-4da0-8c5e-69033d143b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# It creates a pairs list for statistical tests with\n",
    "# the files created by the sampling notebook. Each pair\n",
    "# refers to two dataset with equal number \n",
    "# of samples, but from different executions.\n",
    "# Parameters\n",
    "# - names --> list of file names as (\"nsamples_executionIndex_algorithm.csv\")\n",
    "##############################################\n",
    "def testPairsCreator(algorithms, samples, executionsPerSamples, executionsCbs3):\n",
    "    \n",
    "    testNames = {}\n",
    "    \n",
    "    for algorithm in algorithms:\n",
    "        testNames[algorithm] = []\n",
    "        names = []\n",
    "        if(algorithm == \"cbs3\"):\n",
    "            for j in range(0, executionsCbs3):\n",
    "                    names.append(str(j) + \"_\" + \"0_\"+ algorithm + \".csv/\")\n",
    "            temp_list = list(itertools.combinations_with_replacement(names,2))\n",
    "            temp_list=[(el[0],el[1]) for el in temp_list if el[0]!=el[1]]\n",
    "            testNames[algorithm].extend(temp_list)\n",
    "        else:\n",
    "            for i in samples:\n",
    "                for j in range(0, executionsPerSamples):\n",
    "                    names.append(str(i) + \"_\" + str(j) + \"_\"+ algorithm + \".csv\")\n",
    "            temp = []\n",
    "            last_nsample = names[0].split(\"_\")[0]\n",
    "            for name in names:\n",
    "                nsample = name.split(\"_\")[0]\n",
    "                if(nsample == last_nsample):\n",
    "                    temp.append(name + \"/\")\n",
    "                    last_nsample = nsample\n",
    "                else:\n",
    "                    temp_list = list(itertools.combinations_with_replacement(temp,2))\n",
    "                    temp_list=[(el[0],el[1]) for el in temp_list if el[0]!=el[1]]\n",
    "                    testNames[algorithm].extend(temp_list)\n",
    "                    temp = []\n",
    "                    temp.append(name + \"/\")\n",
    "                    last_nsample = nsample\n",
    "            temp_list = list(itertools.combinations_with_replacement(temp,2))\n",
    "            temp_list=[(el[0],el[1]) for el in temp_list if el[0]!=el[1]]\n",
    "            testNames[algorithm].extend(temp_list)\n",
    "    return testNames\n",
    "\n",
    "##############################################\n",
    "# It analyses the KLD coefficient produced by kld.r\n",
    "# to create a dataframe in which each row, representing \n",
    "# a tested couple of samples, contains  the average\n",
    "# KLD coefficients for each model reaction. The last column\n",
    "# of the dataframe contains the cross-reaction mean for \n",
    "# a tested couple of samples.\n",
    "# Parameters\n",
    "# - modelNames --> list of modelNames\n",
    "# - modelsDict --> models dictionary\n",
    "# - modelReactionsDict --> models reactions dictionary\n",
    "# - samplesNList --> samples list\n",
    "# - pairList --> tested pairs list\n",
    "# - thinningsDict --> thinnings dictionary\n",
    "# - executionsPerSampleSize --> executions per sample size\n",
    "# - executionsCbs3 --> executions of the CBS3 algorithm\n",
    "# - kldFolder --> folder of the KLD coefficients\n",
    "# - avoidBlockedReactions --> if True, the cross-reaction mean\n",
    "# does not take into account the coefficients of blocked reactions\n",
    "##############################################\n",
    "def kldAnalysis(modelNames, modelsDict, \n",
    "               modelReactionsDict, \n",
    "               samplesNList,\n",
    "               pairList,\n",
    "               thinningsDict,\n",
    "               executionsPerSampleSize, executionsCbs3, kldFolder, avoidBlockedReactions):\n",
    "    \n",
    "    \n",
    "    \n",
    "    for modelName in modelNames:\n",
    "            for algorithm in pairList:\n",
    "                numberOfTestPerNSample = len(pairList[algorithm])/len(samplesNList)\n",
    "                for thinning in thinningsDict[algorithm]:\n",
    "                    if(algorithm == \"cbs3\"):\n",
    "                        createFolder(os.path.join(kldFolder, modelName, algorithm + \"groupedBy\" + str(thinning), \"analysis\"))\n",
    "                        df = pd.read_csv(os.path.join(kldFolder, modelName, algorithm + \"groupedBy\" + str(thinning), \"kld.csv\"), index_col = 1)\n",
    "                    else:\n",
    "                        createFolder(os.path.join(kldFolder, modelName, algorithm + \"Thinning\" + str(thinning), \"analysis\"))\n",
    "                        df = pd.read_csv(os.path.join(kldFolder, modelName, algorithm + \"Thinning\" + str(thinning), \"kld.csv\"), index_col = 1)\n",
    "                        \n",
    "                    df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],\n",
    "                            axis = 1, inplace = True)\n",
    "                    nReaction = len(modelReactionsDict[modelName])\n",
    "                    blockedR = cb.flux_analysis.find_blocked_reactions(modelsDict[modelName])\n",
    "                    nBlockedR = len(blockedR)\n",
    "                    columns = [\"Samples\"]\n",
    "                    for col in df.columns:\n",
    "                        columns.append(col)\n",
    "                    columns.append(\"Total\")\n",
    "                    dfResult = pd.DataFrame(columns =  columns)\n",
    "\n",
    "                    for column in df.columns:\n",
    "                        summ = 0\n",
    "                        i = 0\n",
    "                        res = []\n",
    "                        for cell in df[column]:\n",
    "                            summ = summ + cell\n",
    "                            i = i + 1\n",
    "                            if(algorithm != \"cbs3\"):\n",
    "                                if(i == numberOfTestPerNSample):\n",
    "                                    res.append(summ/numberOfTestPerNSample)\n",
    "                                    i = 0\n",
    "                                    summ = 0\n",
    "                        if(algorithm == \"cbs3\"):\n",
    "                            res.append(summ/len(column))\n",
    "                        dfResult[column] = res\n",
    "\n",
    "                    sampleList = []\n",
    "                    if(algorithm != \"cbs3\"):\n",
    "                        for i in samplesNList:\n",
    "                            sampleList.append(i)\n",
    "                        dfResult[\"Samples\"] = sampleList\n",
    "                    else:\n",
    "                        dfResult[\"Samples\"] = [0]\n",
    "                    dfResult = dfResult.set_index(\"Samples\")\n",
    "                    res = []\n",
    "                    for index, row in dfResult.iterrows():\n",
    "                        summ = 0\n",
    "                        for i in range(0, nReaction):\n",
    "                            if(avoidBlockedReactions):\n",
    "                                if(modelReactionsDict[modelName][i] not in blockedR):\n",
    "                                    summ = summ + row[i]\n",
    "                            else:\n",
    "                                summ = summ + row[i]\n",
    "                        res.append(summ/(nReaction - nBlockedR))\n",
    "                    dfResult[\"Total\"] = res\n",
    "                    if(algorithm == \"cbs3\"):\n",
    "                        dfResult.to_csv(os.path.join(kldFolder, modelName, algorithm + \"groupedBy\" + str(thinning), \"analysis\", \"kld.csv\"))\n",
    "                    else:\n",
    "                        dfResult.to_csv(os.path.join(kldFolder, modelName, algorithm + \"Thinning\" + str(thinning), \"analysis\", \"kld.csv\"))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbfaf3d3-dbf6-488f-b694-377059e2a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"achr\", \"optgp\", \"chrr\", \"cbs3\"]\n",
    "\n",
    "thinningsDict = {}\n",
    "\n",
    "samplesNList = []\n",
    "for i in range(1000, 30001, 1000):\n",
    "    samplesNList.append(i)\n",
    "    \n",
    "executionsPerSampleSize = 20\n",
    "executionsCbs3 = 20\n",
    "\n",
    "\n",
    "thinningsDict[\"achr\"] = [1, 10, 100]\n",
    "thinningsDict[\"optgp\"] = [1, 10, 100]\n",
    "thinningsDict[\"chrr\"] = [1, 10, 100]\n",
    "thinningsDict[\"cbs3\"] = [1000]\n",
    "\n",
    "pairList = testPairsCreator(algorithms, samplesNList, executionsPerSampleSize, executionsCbs3)\n",
    "\n",
    "kldFolder = \"../../results/KLD/\"\n",
    "\n",
    "avoidBlockedReactions = True\n",
    "        \n",
    "kldAnalysis(modelNames, modelsDict, \n",
    "               modelReactionsDict, \n",
    "               samplesNList,\n",
    "               pairList,\n",
    "               thinningsDict,\n",
    "               executionsPerSampleSize, executionsCbs3, kldFolder, avoidBlockedReactions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
