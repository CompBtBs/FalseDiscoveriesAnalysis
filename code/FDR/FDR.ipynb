{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d923eef0-10de-488e-9e39-160545758a8e",
   "metadata": {},
   "source": [
    "FDR.ipynb  False Discovery Rate analysis\n",
    "\n",
    "    Version 1.0 February 2023\n",
    "\n",
    "    Authors: \n",
    "        - Bruno G. Galuzzi <bruno.galuzzi@unimib.it> (Department of Biotechnology and Biosciences, University of Milano-Bicocca)\n",
    "        - Luca Milazzo <l.milazzo1@campus.unimib.it> (Department of Informatics, Systems, and Communications, University of Milano-Bicocca)\n",
    "        - Chiara Damiani <chiara.damiani@unimib.it> (Department of Biotechnology and Biosciences, University of Milano-Bicocca)\n",
    "\n",
    "    Prerequisites and parameters:\n",
    "         - Install all the modules listed under the \"Libraries\" chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f653a-a54c-40e7-b975-2038deb2f6ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e98112f-eb84-4c44-bf3e-8bc23c5a4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra as cb\n",
    "import logging\n",
    "logging.basicConfig(filename=\"log.txt\"  , level=logging.INFO)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd52b5-8a35-4222-bccc-c3140816127d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5e0a86-8bf2-46a2-bf01-84476842dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\"ENGRO 1\", \"ENGRO 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56ba11c6-4f53-484f-b1c6-2c706786222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Create a folder if it doesn't already exist\n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def createFolder(path):\n",
    "    if not os.path.exists(path):\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f0f68-692e-46b2-b3dc-b431d2077982",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51aeede8-a2a1-4c5b-9f0c-99b58db76276",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Load the models files (.xml)\n",
    "# Parameters\n",
    "# - modelNames --> list of models names that must\n",
    "# match the file names\n",
    "# - modelFolder --> the folder containing the \n",
    "# models files\n",
    "##############################################\n",
    "def loadModels(modelNames, modelFolder):\n",
    "    models = {}\n",
    "    for modelName in modelNames:\n",
    "        files = os.listdir(modelFolder)\n",
    "        found = False\n",
    "        for file in files:\n",
    "            filename, extension = os.path.splitext(file)\n",
    "            if(filename == modelName):\n",
    "                found = True\n",
    "                break\n",
    "        if(found):\n",
    "            if(extension == \".xml\"):\n",
    "                models[modelName] = cb.io.read_sbml_model(modelFolder + filename + extension)\n",
    "            else:\n",
    "                raise ImportError('Model file extension not supported')\n",
    "        else:\n",
    "            raise FileNotFoundError('File not found')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a273e0a4-f456-43a2-8b1c-d20ded7ec25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsDict = loadModels(modelNames, \"../../models/\")\n",
    "modelReactionsDict = {}\n",
    "for modelName in modelNames:\n",
    "    listReactions = []\n",
    "    for reaction in modelsDict[modelName].reactions:\n",
    "        listReactions.append(reaction.id)\n",
    "    modelReactionsDict[modelName] = listReactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24ede6-e448-43ac-a10e-cda69b983940",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Similarity tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be758cf2-8cdb-451f-befe-7da4074b35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# \n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def kstest(s1, s2):\n",
    "    return stats.ks_2samp(s1, s2)\n",
    "\n",
    "##############################################\n",
    "# \n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def mannwhitney(s1, s2):\n",
    "    return stats.mannwhitneyu(s1, s2)\n",
    "\n",
    "##############################################\n",
    "# It creates a pairs list for statistical tests with\n",
    "# the files created by the sampling notebook. Each pair\n",
    "# refers to two dataset with equal number \n",
    "# of samples, but from different executions.\n",
    "# Parameters\n",
    "# - names --> list of file names as (\"nsamples_executionIndex_algorithm.csv\")\n",
    "##############################################\n",
    "def testPairsCreator(algorithms, samples, executionsPerSamples):\n",
    "    \n",
    "    testNames = {}\n",
    "    \n",
    "    for algorithm in algorithms:\n",
    "        testNames[algorithm] = []\n",
    "        names = []\n",
    "        if(samples == [-1]):\n",
    "            for j in range(0, executionsPerSamples):\n",
    "                    names.append(str(j) + \"_\" + \"0_\"+ algorithm + \".csv\")\n",
    "        else:\n",
    "            for i in samples:\n",
    "                for j in range(0, executionsPerSamples):\n",
    "                    names.append(str(i) + \"_\" + str(j) + \"_\"+ algorithm + \".csv\")\n",
    "        temp = []\n",
    "        last_nsample = names[0].split(\"_\")[0]\n",
    "        for name in names:\n",
    "            nsample = name.split(\"_\")[0]\n",
    "            if(nsample == last_nsample):\n",
    "                temp.append(name + \"/\")\n",
    "                last_nsample = nsample\n",
    "            else:\n",
    "                temp_list = list(itertools.combinations_with_replacement(temp,2))\n",
    "                temp_list=[(el[0],el[1]) for el in temp_list if el[0]!=el[1]]\n",
    "                testNames[algorithm].extend(temp_list)\n",
    "                temp = []\n",
    "                temp.append(name + \"/\")\n",
    "                last_nsample = nsample\n",
    "        temp_list = list(itertools.combinations_with_replacement(temp,2))\n",
    "        temp_list=[(el[0],el[1]) for el in temp_list if el[0]!=el[1]]\n",
    "        testNames[algorithm].extend(temp_list)\n",
    "    return testNames\n",
    "\n",
    "\n",
    "##############################################\n",
    "# \n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def similarityTest(modelNames, modelsDict, modelReactionsDict, pairList, tests, thinnings, groupedBy,\n",
    "                   elementPath, resultPath):\n",
    "    \n",
    "    createFolder(resultPath)\n",
    "    \n",
    "    for modelName in modelNames:\n",
    "        createFolder(resultPath + modelName)\n",
    "        for algorithm in pairList:\n",
    "            for thinning in thinnings:\n",
    "                for test in tests:\n",
    "                    createFolder(resultPath + modelName + \"/\" + test)\n",
    "                    dfColumns = ['testName']\n",
    "                    dfColumns.extend(modelReactionsDict[modelName])\n",
    "                    resultDf = pd.DataFrame(columns = dfColumns)\n",
    "                    lenDf = 0\n",
    "                    nReactions = len(modelReactionsDict[modelName])\n",
    "                    for pair in pairList[algorithm]:\n",
    "                        if(thinning == -1):\n",
    "                            samplePath = elementPath + modelName + \"/\" + algorithm + \"groupedBy\" + str(groupedBy)+ \"/\"\n",
    "                        else:\n",
    "                            samplePath = elementPath + modelName + \"/\" + algorithm + \"Thinning\" + str(thinning) + \"/\"\n",
    "                        test_name = (pair[0] + pair[1]).split(\"/\")\n",
    "                        del test_name[-1]\n",
    "                        formattedNameEl1 = test_name[0].split('_')\n",
    "                        formattedNameEl2 = test_name[1].split('_')\n",
    "                        res = [formattedNameEl1[0] + \"_\" + formattedNameEl1[1] + \n",
    "                               \"_\" + formattedNameEl2[0] + \"_\" + formattedNameEl2[1]]\n",
    "                        logging.info(\"Executing test: \" + res[0])\n",
    "                        logging.info(\"Files: \" + samplePath + test_name[0] + \n",
    "                              \" and \" + samplePath + test_name[1])\n",
    "                        s1 = pd.read_csv(samplePath + test_name[0], index_col = 0)\n",
    "                        s2 = pd.read_csv(samplePath + test_name[1], index_col = 0)\n",
    "                        for h in range(nReactions):\n",
    "                            if(test == \"kstest\"):\n",
    "                                res.append(kstest(s1.iloc[:, h], s2.iloc[:, h]).pvalue)\n",
    "                            elif(test == \"mannwhitney\"):\n",
    "                                res.append(mannwhitney(s1.iloc[:, h], s2.iloc[:, h]).pvalue)\n",
    "                            else:\n",
    "                                raise NotImplementedError('Algorithm not supported')\n",
    "                        resultDf.loc[lenDf] = res\n",
    "                        lenDf = lenDf + 1\n",
    "                    if(thinning == -1):\n",
    "                        resultDf.set_index('testName').to_csv(resultPath + modelName + \"/\" + \n",
    "                                                              test + \"/\" + algorithm + \"groupedBy\" + str(groupedBy) + \".csv\")\n",
    "                    else:\n",
    "                        resultDf.set_index('testName').to_csv(resultPath + modelName + \"/\" + \n",
    "                                                              test + \"/\" + algorithm + \"Thinning\" + str(thinning) + \".csv\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be4d92-807f-4bfc-8128-5de1b724d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"achr\", \"optgp\", \"chrr\"]\n",
    "\n",
    "samplesNList = []\n",
    "for i in range(1000, 30001, 1000):\n",
    "    samplesNList.append(i)\n",
    "    \n",
    "executionsPerSampleSize = 20\n",
    "\n",
    "thinnings = [1, 10, 100]\n",
    "\n",
    "testNames = testPairsCreator(algorithms, samplesNList, executionsPerSampleSize)\n",
    "\n",
    "tests = [\"kstest\", \"mannwhitney\"]\n",
    "\n",
    "samplesFolder = \"../../samples/\"\n",
    "\n",
    "resultFolder = \"../../results/FDR/\"\n",
    "\n",
    "similarityTest(modelNames, modelsDict, modelReactionsDict, testNames, tests, thinnings, samplesFolder, resultFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caecbbd-6671-4863-bede-a25324a533cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"cbs3\"]\n",
    "\n",
    "samplesNList = [-1]\n",
    "\n",
    "groupedBy = 1000\n",
    "\n",
    "executions = 20\n",
    "\n",
    "thinnings = [-1]\n",
    "\n",
    "testNames = testPairsCreator(algorithms, samplesNList, executions)\n",
    "\n",
    "tests = [\"kstest\", \"mannwhitney\"]\n",
    "\n",
    "samplesFolder = \"../../samples/\"\n",
    "\n",
    "resultFolder = \"../../results/FDR/\"\n",
    "\n",
    "similarityTest(modelNames, modelsDict, modelReactionsDict, testNames, tests, thinnings, groupedBy, \n",
    "               samplesFolder, resultFolder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
