{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d923eef0-10de-488e-9e39-160545758a8e",
   "metadata": {},
   "source": [
    "FDR.ipynb  False Discovery Rate analysis\n",
    "\n",
    "    Version 1.0 February 2023\n",
    "\n",
    "    Authors: \n",
    "        - Bruno G. Galuzzi <bruno.galuzzi@unimib.it> (Department of Biotechnology and Biosciences, University of Milano-Bicocca)\n",
    "        - Luca Milazzo <l.milazzo1@campus.unimib.it> (Department of Informatics, Systems, and Communications, University of Milano-Bicocca)\n",
    "        - Chiara Damiani <chiara.damiani@unimib.it> (Department of Biotechnology and Biosciences, University of Milano-Bicocca)\n",
    "\n",
    "    Prerequisites and parameters:\n",
    "         - Install all the modules listed under the \"Libraries\" chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f653a-a54c-40e7-b975-2038deb2f6ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e98112f-eb84-4c44-bf3e-8bc23c5a4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra as cb\n",
    "import logging\n",
    "logging.basicConfig(filename=\"log.txt\"  , level=logging.INFO)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import combinations_with_replacement\n",
    "import scipy.stats as stats\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd52b5-8a35-4222-bccc-c3140816127d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5e0a86-8bf2-46a2-bf01-84476842dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNames = [\"ENGRO 1\", \"ENGRO 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56ba11c6-4f53-484f-b1c6-2c706786222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Create a folder if it doesn't already exist\n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def createFolder(path):\n",
    "    if not os.path.exists(path):\n",
    "            os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f0f68-692e-46b2-b3dc-b431d2077982",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51aeede8-a2a1-4c5b-9f0c-99b58db76276",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Load the models files (.xml)\n",
    "# Parameters\n",
    "# - modelNames --> list of models names that must\n",
    "# match the file names\n",
    "# - modelFolder --> the folder containing the \n",
    "# models files\n",
    "##############################################\n",
    "def loadModels(modelNames, modelFolder):\n",
    "    models = {}\n",
    "    for modelName in modelNames:\n",
    "        files = os.listdir(modelFolder)\n",
    "        found = False\n",
    "        for file in files:\n",
    "            filename, extension = os.path.splitext(file)\n",
    "            if(filename == modelName):\n",
    "                found = True\n",
    "                break\n",
    "        if(found):\n",
    "            if(extension == \".xml\"):\n",
    "                models[modelName] = cb.io.read_sbml_model(modelFolder + filename + extension)\n",
    "            else:\n",
    "                raise ImportError('Model file extension not supported')\n",
    "        else:\n",
    "            raise FileNotFoundError('File not found')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a273e0a4-f456-43a2-8b1c-d20ded7ec25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsDict = loadModels(modelNames, \"../../models/\")\n",
    "modelReactionsDict = {}\n",
    "for modelName in modelNames:\n",
    "    listReactions = []\n",
    "    for reaction in modelsDict[modelName].reactions:\n",
    "        listReactions.append(reaction.id)\n",
    "    modelReactionsDict[modelName] = listReactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24ede6-e448-43ac-a10e-cda69b983940",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Similarity tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be758cf2-8cdb-451f-befe-7da4074b35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# \n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def kstest(s1, s2):\n",
    "    return stats.ks_2samp(s1, s2)\n",
    "\n",
    "##############################################\n",
    "# \n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def mannwhitney(s1, s2):\n",
    "    return stats.mannwhitneyu(s1, s2)\n",
    "\n",
    "##############################################\n",
    "# It creates a pairs list for statistical tests with\n",
    "# the files created by the sampling notebook. Each pair\n",
    "# refers to two dataset with equal number \n",
    "# of samples, but from different executions.\n",
    "# Parameters\n",
    "# - names --> list of file names as (\"nsamples_executionIndex_algorithm.csv\")\n",
    "##############################################\n",
    "def testPairsCreator(algorithms, samples, executionsPerSamples):\n",
    "    \n",
    "    testNames = {}\n",
    "    \n",
    "    for algorithm in algorithms:\n",
    "        testNames[algorithm] = []\n",
    "        names = []\n",
    "        if(algorithm == \"cbs3\"):\n",
    "            for j in range(0, executionsPerSamples):\n",
    "                    names.append(str(j) + \"_\" + \"0_\"+ algorithm + \".csv\")\n",
    "        else:\n",
    "            for i in samples:\n",
    "                for j in range(0, executionsPerSamples):\n",
    "                    names.append(str(i) + \"_\" + str(j) + \"_\"+ algorithm + \".csv\")\n",
    "        temp = []\n",
    "        last_nsample = names[0].split(\"_\")[0]\n",
    "        for name in names:\n",
    "            nsample = name.split(\"_\")[0]\n",
    "            if(nsample == last_nsample):\n",
    "                temp.append(name + \"/\")\n",
    "                last_nsample = nsample\n",
    "            else:\n",
    "                temp_list = list(itertools.combinations_with_replacement(temp,2))\n",
    "                temp_list=[(el[0],el[1]) for el in temp_list if el[0]!=el[1]]\n",
    "                testNames[algorithm].extend(temp_list)\n",
    "                temp = []\n",
    "                temp.append(name + \"/\")\n",
    "                last_nsample = nsample\n",
    "        temp_list = list(itertools.combinations_with_replacement(temp,2))\n",
    "        temp_list=[(el[0],el[1]) for el in temp_list if el[0]!=el[1]]\n",
    "        testNames[algorithm].extend(temp_list)\n",
    "    return testNames\n",
    "\n",
    "\n",
    "##############################################\n",
    "# \n",
    "# Parameters\n",
    "# - path --> new folder path\n",
    "##############################################\n",
    "def similarityTest(modelNames, modelsDict, modelReactionsDict, pairList, tests, thinningsDict,\n",
    "                   elementPath, resultPath):\n",
    "    \n",
    "    createFolder(resultPath)\n",
    "    \n",
    "    for modelName in modelNames:\n",
    "        createFolder(resultPath + modelName)\n",
    "        for algorithm in pairList:\n",
    "            for thinning in thinningsDict[algorithm]:\n",
    "                for test in tests:\n",
    "                    createFolder(resultPath + modelName + \"/\" + test)\n",
    "                    dfColumns = ['testName']\n",
    "                    dfColumns.extend(modelReactionsDict[modelName])\n",
    "                    resultDf = pd.DataFrame(columns = dfColumns)\n",
    "                    lenDf = 0\n",
    "                    nReactions = len(modelReactionsDict[modelName])\n",
    "                    for pair in pairList[algorithm]:\n",
    "                        if(algorithm == \"cbs3\"):\n",
    "                            samplePath = elementPath + modelName + \"/\" + algorithm + \"groupedBy\" + str(thinning)+ \"/\"\n",
    "                        else:\n",
    "                            samplePath = elementPath + modelName + \"/\" + algorithm + \"Thinning\" + str(thinning) + \"/\"\n",
    "                        test_name = (pair[0] + pair[1]).split(\"/\")\n",
    "                        del test_name[-1]\n",
    "                        formattedNameEl1 = test_name[0].split('_')\n",
    "                        formattedNameEl2 = test_name[1].split('_')\n",
    "                        res = [formattedNameEl1[0] + \"_\" + formattedNameEl1[1] + \n",
    "                               \"_\" + formattedNameEl2[0] + \"_\" + formattedNameEl2[1]]\n",
    "                        logging.info(\"Executing test: \" + res[0])\n",
    "                        logging.info(\"Files: \" + samplePath + test_name[0] + \n",
    "                              \" and \" + samplePath + test_name[1])\n",
    "                        s1 = pd.read_csv(samplePath + test_name[0], index_col = 0)\n",
    "                        s2 = pd.read_csv(samplePath + test_name[1], index_col = 0)\n",
    "                        for h in range(nReactions):\n",
    "                            if(test == \"kstest\"):\n",
    "                                res.append(kstest(s1.iloc[:, h], s2.iloc[:, h]).pvalue)\n",
    "                            elif(test == \"mannwhitney\"):\n",
    "                                res.append(mannwhitney(s1.iloc[:, h], s2.iloc[:, h]).pvalue)\n",
    "                            else:\n",
    "                                raise NotImplementedError('Algorithm not supported')\n",
    "                        resultDf.loc[lenDf] = res\n",
    "                        lenDf = lenDf + 1\n",
    "                    if(algorithm == \"cbs3\"):\n",
    "                        resultDf.set_index('testName').to_csv(resultPath + modelName + \"/\" + \n",
    "                                                              test + \"/\" + algorithm + \"groupedBy\" + str(thinning) + \".csv\")\n",
    "                    else:\n",
    "                        resultDf.set_index('testName').to_csv(resultPath + modelName + \"/\" + \n",
    "                                                              test + \"/\" + algorithm + \"Thinning\" + str(thinning) + \".csv\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be4d92-807f-4bfc-8128-5de1b724d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"achr\", \"optgp\", \"chrr\", \"cbs3\"]\n",
    "\n",
    "samplesNList = []\n",
    "for i in range(1000, 30001, 1000):\n",
    "    samplesNList.append(i)\n",
    "    \n",
    "executionsPerSampleSize = 20\n",
    "\n",
    "thinningsDict[\"achr\"] = [1, 10, 100]\n",
    "thinningsDict[\"optgp\"] = [1, 10, 100]\n",
    "thinningsDict[\"chrr\"] = [1, 10, 100]\n",
    "thinningsDict[\"cbs3\"] = [1000]\n",
    "\n",
    "pairList = testPairsCreator(algorithms, samplesNList, executionsPerSampleSize)\n",
    "\n",
    "tests = [\"kstest\", \"mannwhitney\"]\n",
    "\n",
    "samplesFolder = \"../../samples/\"\n",
    "\n",
    "resultFolder = \"../../results/FDR/\"\n",
    "\n",
    "similarityTest(modelNames, modelsDict, \n",
    "               modelReactionsDict, pairList, \n",
    "               tests, thinningsDict,\n",
    "               samplesFolder, resultFolder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b01d92-b0d6-473d-a1f8-f95387c33ae2",
   "metadata": {},
   "source": [
    "# Fold change and fluxes mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf584d3-3bb1-4d53-a77e-94065f6e00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(samplesFolder, resultFolder):\n",
    "    for fname in glob.glob(samplesFolder + \"*.csv\"):\n",
    "        df = pd.read_csv(samplesFolder + fname, index_col = 0)\n",
    "        dfres = pd.DataFrame(df.mean(), columns = [ \"mean\"])\n",
    "        dfres.to_csv(resultFolder + fname)\n",
    "    pass\n",
    "\n",
    "def foldChange(modelNames, modelsDict, \n",
    "               modelReactionsDict, pairList,\n",
    "               thinningsDict,\n",
    "               samplesFolder, resultPathMean, resultPathFc):\n",
    "    \n",
    "    createFolder(resultPathMean)\n",
    "    createFolder(resultPathFc)\n",
    "    \n",
    "    for modelName in modelNames:\n",
    "        logging.info(\"Computing fold change: \" + modelName)\n",
    "        createFolder(resultPathMean + modelName)\n",
    "        createFolder(resultPathFc + modelName)\n",
    "        for algorithm in pairList:\n",
    "            for thinning in thinningsDict[algorithm]:\n",
    "                if(algorithm == \"cbs3\"):\n",
    "                    logging.info(\"Computing means: \" + algorithm + \" - groupedby\" + str(thinning))\n",
    "                    createFolder(resultPathMean + modelName + algorithm + \"groupedBy\" + str(thinning)+ \"/\")\n",
    "                    mean(samplesFolder + modelName + \"/\" + algorithm + \"groupedBy\" + str(thinning)+ \"/\",\n",
    "                         resultPathMean + modelName + algorithm + \"groupedBy\" + str(thinning)+ \"/\")\n",
    "                else:\n",
    "                    logging.info(\"Computing means: \" + algorithm + \" - thinning\" + str(thinning))\n",
    "                    createFolder(resultPathMean + modelName + algorithm + \"Thinning\" + str(thinning)+ \"/\")\n",
    "                    mean(samplesFolder + modelName + \"/\" + algorithm + \"Thinning\" + str(thinning) + \"/\", \n",
    "                         resultPathMean + modelName + algorithm + \"Thinning\" + str(thinning)+ \"/\")\n",
    "                \n",
    "                dfColumns = ['testName']\n",
    "                dfColumns.extend(modelReactionsDict[modelName])\n",
    "                nReactions = len(modelReactionsDict[modelName])\n",
    "                resultDf = pd.DataFrame(columns = dfColumns)\n",
    "                lenDf = 0\n",
    "                for pair in pairList[algorithm]:\n",
    "                    if(algorithm == \"cbs3\"):\n",
    "                        samplePath = samplesFolder + modelName + \"/\" + algorithm + \"groupedBy\" + str(thinning)+ \"/\"\n",
    "                    else:\n",
    "                        samplePath = samplesFolder + modelName + \"/\" + algorithm + \"Thinning\" + str(thinning) + \"/\"\n",
    "                    test_name = (pair[0] + pair[1]).split(\"/\")\n",
    "                    del test_name[-1]\n",
    "                    formattedNameEl1 = test_name[0].split('_')\n",
    "                    formattedNameEl2 = test_name[1].split('_')\n",
    "                    res = [formattedNameEl1[0] + \"_\" + formattedNameEl1[1] + \"_\" + \n",
    "                           formattedNameEl2[0] + \"_\" + formattedNameEl2[1]]\n",
    "                    s1 = pd.read_csv(samplePath + test_name[0], index_col = 0)\n",
    "                    s2 = pd.read_csv(samplePath + test_name[1], index_col = 0)\n",
    "                    for index in range (0, nReactions):\n",
    "                        a = s1.iloc[index][\"mean\"]\n",
    "                        b = s2.iloc[index][\"mean\"]\n",
    "                        res.append(abs((a-b)/b))\n",
    "                    resultDf.loc[lenDf] = res\n",
    "                    lenDf = lenDf + 1\n",
    "                if(algorithm == \"cbs3\"):\n",
    "                    resultDf.set_index('testName').to_csv(resultPathFc + modelName + \"/\" + \n",
    "                                                          algorithm + \"groupedBy\" + str(thinning) + \".csv\")\n",
    "                else:\n",
    "                    resultDf.set_index('testName').to_csv(resultPathFc + modelName + \"/\"+  \n",
    "                                                          algorithm + \"Thinning\" + str(thinning) + \".csv\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142f1c8-419b-412a-911b-d29bbdbb0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"achr\", \"optgp\", \"chrr\", \"cbs3\"]\n",
    "\n",
    "samplesNList = []\n",
    "for i in range(1000, 30001, 1000):\n",
    "    samplesNList.append(i)\n",
    "    \n",
    "executionsPerSampleSize = 20\n",
    "\n",
    "thinningsDict[\"achr\"] = [1, 10, 100]\n",
    "thinningsDict[\"optgp\"] = [1, 10, 100]\n",
    "thinningsDict[\"chrr\"] = [1, 10, 100]\n",
    "thinningsDict[\"cbs3\"] = [1000]\n",
    "\n",
    "pairList = testPairsCreator(algorithms, samplesNList, executionsPerSampleSize)\n",
    "\n",
    "samplesFolder = \"../../samples/\"\n",
    "\n",
    "resultFolderMean = \"../../results/mean/\"\n",
    "\n",
    "resultFolderFc = \"../../results/foldChange/\"\n",
    "\n",
    "foldChange(modelNames, modelsDict, \n",
    "               modelReactionsDict, pairList,\n",
    "               thinningsDict,\n",
    "               samplesFolder, resultFolderMean, resultFolderFc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58620f91-e185-4106-8c15-b39841af1ce3",
   "metadata": {},
   "source": [
    "# False Discovery Rate (FDR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7efe75-9994-47aa-8658-3f54978d448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [\"adjusted/\", \"adjustedConvergenceFilter/\", \n",
    "        \"adjustedFoldChange/\", \"adjustedFoldChangeConvergenceFilter/\", \n",
    "        \"notAdjusted/\" , \"notAdjustedConvergenceFilter/\" , \n",
    "        \"notAdjustedFoldChange/\" , \"notAdjustedFoldChangeConvergenceFilter/\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
